title: Building an SGX profiler for Gramine
---
author: Pawe≈Ç Marczewski
---
pub_date: 2022-05-10
---
class: svg-invert
---
body:

*This blog post describes how I developed the SGX profiling mode for Gramine.
Thanks to (TODO) for reviewing.*

As mentioned in [the last blog post][prev], [Gramine] is a framework for running
Linux applications under non-standard environments. It's quite possible that
running an application under Gramine will have some performance overhead. By
using a profiler, we can find out what it is, and how to fix it: we might be
able to fix the problem in Gramine, or, if the inefficiency is inherent to the
environment (e.g. the way SGX memory is managed), it might be possible to tweak
or patch the application to do something else.

[Gramine]: https://gramineproject.io
[prev]: https://gramineproject.io/blog/gdb-support-in-gramine/

Unfortunately, similar to GDB, Gramine's SGX mode does not support profiling
tools out of the box: by default, the code executing inside an SGX enclave is
opaque to external tools. This blog posts describes how I built my own solution
for profiling Gramine.

## Using `perf`

Under Linux, a pretty good option for profiling is to use [perf]. `perf` is a
Linux profiler built into the Linux kernel. By running `perf record`, we can ask
Linux to record a trace of program execution. Then, `perf report` will interpret
that data and show time spent in each function.

[perf]: https://perf.wiki.kernel.org/index.php/Main_Page

![Screenshot of perf report](perf-report.png)

The architecture of `perf` is pretty interesting: the recording tool, `perf
record`, actually asks the Linux kernel to monitor the process (using the
[perf_event_open] system call). Then, Linux kernel records *samples* (which
typically contain some program state, like instruction pointer) and forwards
them to `perf record`, which saves them to a file. Afterwards, `perf report`
processes the data, resolves function names, and displays statistics.

[perf_event_open]: https://man7.org/linux/man-pages/man2/perf_event_open.2.html

![Diagram: perf record records samples, perf report interprets them](diagram-perf.svg)

`perf` is a very powerful tool. Apart from the basic statistics shown above,
it's possible to gather information about kernel execution, detailed processor
performance (e.g. cache misses), system calls, and much more. (See [Brendan
Gregg's `perf` page][brendangregg] for various examples).

[brendangregg]: https://www.brendangregg.com/perf.html

In fact, when I ran Gramine in the direct (non-SGX) mode, `perf` already worked
out of the box! This might be surprising given the fact that Gramine loads
various binaries on its own: [GDB needed some extra help] figuring out where the
files are mapped, even in the direct mode. `perf`, however, figures that out by
recording `mmap` syscalls made by Gramine.

In SGX mode, however, things are not looking good. It turns out that `perf` will
assign all time spent in enclave to a function called `async_exit_pointer`:

![Screenshot of perf report for SGX enclave. Most time is spent in async_exit_pointer.](perf-report-aex.png)

As explained in the [previous article about GDB][prev], AEP is where the process
ends up when enclave execution is interrupted. It turns out that the same
limitation applies to `perf`. In order for Linux to record a sample, the process
must be temporarily stopped first (usually, by a timer interrupt).

This sounds pretty difficult to work around, since the samples are being
recorded by Linux kernel. It might be possible to add better `perf` support to
the SGX driver in kernel, but I didn't feel experienced enough to attempt that.

## Poor man's profiler

A very simple method of profiling (if it can even be called that) is to use GDB:
run the program, hit Ctrl-C a few times and display the backtrace. This is known
as [poor man's profiler][pmp]. If there is an obvious performance issue,
repeating that a few times should be enough to notice it. Given how Gramine
already has good GDB support, the idea sounded promising.

[pmp]: (https://readwrite.com/using-gdb-as-a-poor-mans-profi/)

However, this method is useless for any kind of qualitative results: we will not
notice whether some function takes 1%, 5% or 15% of the execution time. There
have been attempts to [turn "poor man's profiler" into a script][pmp-script]
that repeatedly asks GDB to stop the process and display backtrace, but such a
script still has massive overhead. In Gramine, it's difficult to take more than
a few samples per second.

[pmp-script]: https://poormansprofiler.org/

## Writing my own profiler

Still, this failed attempt gave me a better idea: why couldn't Gramine take the
samples by itself? We already have the code running at the Async Exit Pointer
(AEP) handler, and we know this handler executes at least once every 4
milliseconds (default Linux scheduler interval). What's more, thanks to the GDB
integration, I already know how to extract the instruction pointer value from
enclave.

That was the first version of the SGX profiler: in the AEP handler, Gramine
[retrieved the instruction pointer value and recorded it in a hash
map][sgx-profile-old]. Then, on process exit, it dumped the hash map of executed
code addresses.

[sgx-profile-old]: https://github.com/pwmarcz/graphene/blob/423b837358f6224c480e51b240437adc2798c668/Pal/src/host/Linux-SGX/sgx_profile.c#L205

The addresses by itself might not tell us much, but we actually know which code
they correspond to. Thanks to the GDB integration, we maintain a list of loaded
binaries, which we also can dump to a file. Then, determining the function name
is a matter of using a right tool. I wrote a [helper Python script][helper] that
performed this conversion using [pyelftools] and displayed a report.

[helper]: https://github.com/pwmarcz/graphene/blob/423b837358f6224c480e51b240437adc2798c668/Pal/src/host/Linux-SGX/tools/profile-report/profile-report
[pyelftools]: https://github.com/eliben/pyelftools

![Diagram: Gramine's AEP handler records sample, Python tool interprets them](diagram-sgx.svg)

## What about the stack trace?

One major limitation was that I had only information about the *current*
function, and not the function one level higher (not to mention the whole
stack). As a result, I could learn that a generic function like `memset` or
`memcpy` took most of the time, but not where it was called from.

Finding out the stack trace, or even reaching one level higher, is not trivial.
When the code is compiled in debug mode, it might be as easy as [reading the RBP
value (frame pointer)][stack-frames] to find the current stack frame. The stack
frame should contain the return address as well as the *next* frame pointer,
which we can follow further.

[stack-frames]: https://eli.thegreenplace.net/2011/09/06/stack-frame-layout-on-x86-64

However, as the linked article mentions, stack frames on x86-64 Linux (AMD64
ABI) are actually optional. GCC [omits them whenever optimizations are
enabled][gcc-optimize]. We might also be running some functions written in
assembly that do not use a frame pointer. As a result, the RBP register, and
values saved on stack, cannot always be trusted.

[gcc-optimize]: https://gcc.gnu.org/onlinedocs/gcc/Optimize-Options.html

To salvage the situation, I experimented with some heuristics (e.g. is the next
frame pointer properly aligned, and lower than the current frame, but not too
low?) and stopping the stack trace whenever we suspect the value to be garbage.
It still did not work very well.

The *proper* way of recovering the stack trace is recovering the DWARF ([CFI])
information from a binary, and interpreting the stack based on this information.
This can be done using a library like [libdwfl] or [libunwind], either from
another process (e.g. a debugger), or from the process that wishes to examine
itself, for example, to display a stack trace on crash.

[CFI]: https://www.imperialviolet.org/2017/01/18/cfi.html
[libdwfl]: https://sourceware.org/elfutils/
[libunwind]: https://www.nongnu.org/libunwind/

My idea was to invoke one of these libraries inside the AEP handler, find out
the whole stack trace, and write it to a file. I got as far as adapting
`libdwfl` to compile with Gramine, but the code occasionally crashed in a way I
could not debug. I decided that this approach was another dead end: I was
running a lot of complicated code, coming from external library, in what should
be a simple event handler, and in an environment where we avoid even using
`glibc`.

## How does `perf` do it?

At this point, I became curious: how does `perf` retrieve stack traces? The data
gathered by `perf` actually comes from the Linux kernel. Does that mean the
kernel parses all the binaries, and runs `libdwfl` or equivalent in order to
record the full stack trace? That sounds unlikely.

It turns out that `perf record` supports several modes for recording stack traces:

* `--call-graph=fp`, FP (frame pointer mode): in this mode, the Linux kernel
  tries to follow the frame pointer (on x86-64, the RBP register), and record
  the frames. Unfortunately, as explained above, this works only if the compiled
  code uses frame pointers, which is not guaranteed.

* `--call-graph=lbr`: this uses Intel's [Last Branch Records][lbr] feature which
  stores a short stack trace in processor's registers. I haven't really tried
  out this mode.

[lbr]: https://lwn.net/Articles/680985/

* `--call-graph=dwarf`: this indeed uses the DWARF information, but not from
  kernel. In this mode, the kernel *takes a snapshot of all registers, and the
  stack* (8 kilobytes above the current stack pointer) and inserts that in the
  sample. Then, the user-space tool (`perf report`) uses a DWARF library such as
  `libdwfl` in order to parse this information. Instead of digging through a
  live program's memory, we process snapshots of it, possibly long after the
  program exited.

![Diagram: Stack samples are converted to stack trace](diagram-dwarf.svg)

The `call-graph=dwarf` mode looked like a promising approach. I could easily
record the same information: dump all registers, and 8 kilobytes of stack
memory, inside the AEP handler. The hard part would be parsing all these
snapshots using DWARF information. Even with the right library, I was really not
looking forward to that.

But what if I could actually use the existing `perf report` tool?

## Feeding data to `perf report`

That was the final idea that allowed me to (at least partially) stop reinventing
the wheel. I had custom code that recorded samples of a running SGX application.
However, for interpreting these samples, I could actually use the report tool
for `perf`. It would not only save me work, but `perf report` is probably much
better than any custom tool I would create myself.

The main challenge, then, was producing the data in a format understood by `perf
report`. The [perf.data format][format] is somewhat complicated, but
fortunately, most parts are optional and can be omitted. I only needed to record
a few pieces of information:

* for "simple" samples (no stack): instruction pointer value (`PERF_SAMPLE_IP`),
* for samples with stack: additionally, registers (`PERF_SAMPLE_REGS_USER`) and
  stack snapshot (`PERF_SAMPLE_STACK_USER`),
* additionally, an `mmap` event (`PERF_RECORD_MMAP`) whenever the application
  mapped a new executable file.

[format]: https://github.com/torvalds/linux/blob/9be9ed2612b5aedb52a2c240edb1630b6b743cb6/tools/perf/Documentation/perf.data-file-format.txt

I determined the exact details using the following procedure: first, I recorded
a very simple program using `perf record` and disassembled the data file (using
`perf script -D`). Then, I created a program that wrote my own data file with
similar events, and passed it to `perf report`. Using trial and error, I
determined the smallest set of data that allowed `perf report` to run.

## Putting it together

Here, then, is the [SGX profiler] I came up with:

[SGX profiler]: https://gramine.readthedocs.io/en/v1.1/devel/performance.html#sgx-profiling

1. During each AEX event, we [call the sampling function][call-sample] just
   before returning to the enclave.

2. The sampling function ([sgx_profile_sample_aex]), after applying some rate
   limiting, retrieves the information about a thread (in-enclave registers and
   8-kilobyte stack snapshot).

3. This information is [converted to a perf.data format][sgx_perf_data] and
   periodically flushed to disk.

4. In a similar way, we also record all ELF binaries loaded in the enclave
   ([sgx_profile_report_elf]) and convert them to `PERF_RECORD_MMAP` events.

5. The resulting file can be opened in `perf report`, same as "real" files
   produced by Linux.

[call-sample]: https://github.com/gramineproject/gramine/blob/25984464c0add3053fea04a5f1c8b6ed51c204c9/Pal/src/host/Linux-SGX/sgx_entry.S#L91
[sgx_profile_sample_aex]: https://github.com/gramineproject/gramine/blob/25984464c0add3053fea04a5f1c8b6ed51c204c9/Pal/src/host/Linux-SGX/sgx_profile.c#L246
[sgx_perf_data]: https://github.com/gramineproject/gramine/blob/master/Pal/src/host/Linux-SGX/sgx_perf_data.c
[sgx_profile_report_elf]: https://github.com/gramineproject/gramine/blob/25984464c0add3053fea04a5f1c8b6ed51c204c9/Pal/src/host/Linux-SGX/sgx_profile.c#L301

![Screenshot of perf report, with in-enclave functions visible.](perf-report-sgx.png)

The SGX profiler turned out to be pretty useful: it allowed us to track down
various problems that appeared only in SGX mode (and, as such, could not be
traced using "normal" `perf`). One frequently encountered issue was an
application mapping too much memory. On Linux, `mmap` is usually cheap, so you
can afford to map a large area without using it: the actual memory will be
allocated and zeroed only when accessed by application. However, in Gramine's
SGX mode, `mmap` returns existing enclave pages, so they have to be zeroed
first, and that takes time.

I think that gathering my own samples, and producing a `perf.data` file, is a
nice hack (and a great learning opportunity!), but I regret that it was
necessary. I hope that in the future `perf` will work with SGX enclaves
directly.

The Gramine team is also currently working on an alternative: an integration
with [Intel VTune Profiler][vtune]. While this will supplement, not replace, the
`perf` integration, VTune supports SGX natively, so it's likely it will be more
accurate and produce more details.

[vtune]: https://www.intel.com/content/www/us/en/developer/tools/oneapi/vtune-profiler.html
